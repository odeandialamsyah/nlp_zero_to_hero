{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMzR/6+LXA1vgmGQcGx/6Ov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/odeandialamsyah/nlp_zero_to_hero/blob/main/NLP_Zero_to_Hero_Pra_pemrosesan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pre-Processing"
      ],
      "metadata": {
        "id": "MbZiN1BGy5d8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXwcjsmhvGI5",
        "outputId": "7bca7fda-903b-40e0-f88b-6a83873d8088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')      # Untuk tokenisasi\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')  # Untuk daftar stop words\n",
        "nltk.download('wordnet')    # Untuk lemmatization (akan digunakan nanti)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library yang dibutuhkan\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import string\n",
        "from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
        "\n",
        "# Contoh teks mentah\n",
        "teks_mentah = \"NLP adalah bidang yang sangat menarik dan transformatif! Saya suka belajar hal baru di Bandung.\"\n",
        "\n",
        "print(f\"Teks Asli: {teks_mentah}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bS-yCj4vahy",
        "outputId": "4e14734c-42c3-4231-a110-237a1ffb5405"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Teks Asli: NLP adalah bidang yang sangat menarik dan transformatif! Saya suka belajar hal baru di Bandung.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Case Folding (Mengubah Huruf Kecil) ---\n",
        "teks_lowercase = teks_mentah.lower()\n",
        "print(f\"1. Case Folding: {teks_lowercase}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSi5d6mIvnir",
        "outputId": "e54a18e1-889e-4141-bc7b-09a84aaf2a8b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Case Folding: nlp adalah bidang yang sangat menarik dan transformatif! saya suka belajar hal baru di bandung.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Menghilangkan Tanda Baca ---\n",
        "# Membuat tabel translasi untuk menghilangkan tanda baca\n",
        "# string.punctuation berisi semua tanda baca standar\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "teks_tanpa_tanda_baca = teks_lowercase.translate(translator)\n",
        "print(f\"2. Tanpa Tanda Baca: {teks_tanpa_tanda_baca}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8Yg8ch6vvi1",
        "outputId": "f527c08b-9456-45ce-ff8d-26923e0cd7f2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2. Tanpa Tanda Baca: nlp adalah bidang yang sangat menarik dan transformatif saya suka belajar hal baru di bandung\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Menggunakan word_tokenize dari NLTK\n",
        "tokens = word_tokenize(teks_tanpa_tanda_baca)\n",
        "print(f\"3. Tokenisasi: {tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5DwEIdkv1AI",
        "outputId": "8cc831f0-56f2-4588-d489-237db74132b1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. Tokenisasi: ['nlp', 'adalah', 'bidang', 'yang', 'sangat', 'menarik', 'dan', 'transformatif', 'saya', 'suka', 'belajar', 'hal', 'baru', 'di', 'bandung']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Stop Word Removal (Menghilangkan Kata Pengisi) ---\n",
        "# Mengambil daftar stop words bahasa Indonesia dari NLTK\n",
        "# Jika Anda bekerja dengan bahasa Inggris, ganti 'indonesian' dengan 'english'\n",
        "list_stopwords = set(stopwords.words('indonesian'))"
      ],
      "metadata": {
        "id": "Ku2ewxYqxX7K"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_tanpa_stopwords = [kata for kata in tokens if kata not in list_stopwords]\n",
        "print(f\"4. Tanpa Stop Words: {tokens_tanpa_stopwords}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJFL6oEhxID8",
        "outputId": "be063fd8-767b-45e8-b25f-54ee43cc6f8b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4. Tanpa Stop Words: ['nlp', 'bidang', 'menarik', 'transformatif', 'suka', 'belajar', 'bandung']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Stemming (Opsional, lebih cepat) ---\n",
        "# Menggunakan PorterStemmer (umumnya untuk bahasa Inggris,\n",
        "# untuk Bahasa Indonesia ada Sastrawi atau InStem)\n",
        "# Untuk demo, kita pakai PorterStemmer saja untuk melihat konsepnya\n",
        "# atau kita bisa skip dulu untuk bahasa Indonesia jika tidak ada stemmer yang relevan\n",
        "# For Indonesian, you'd typically use libraries like Sastrawi for proper stemming.\n",
        "# Let's use a placeholder and explain:\n",
        "# from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "# factory = StemmerFactory()\n",
        "# stemmer_id = factory.create_stemmer()\n",
        "# tokens_stemmed = [stemmer_id.stem(kata) for kata in tokens_tanpa_stopwords]\n",
        "\n",
        "# Karena NLTK PorterStemmer tidak cocok untuk B.Indonesia,\n",
        "# kita akan lewati stemming untuk demonstrasi B.Indonesia dan langsung ke Lemmatization\n",
        "# atau hanya menunjukkan konsepnya jika pakai PorterStemmer.\n",
        "# Kita tunjukkan contoh PorterStemmer dengan kata berbahasa Inggris untuk ilustrasi:\n",
        "porter = PorterStemmer()\n",
        "example_words_en = [\"running\", \"runs\", \"runner\", \"fairly\"]\n",
        "stemmed_examples = [porter.stem(w) for w in example_words_en]\n",
        "print(f\"\\n5. Contoh Stemming (English): {stemmed_examples}\") # output: ['run', 'run', 'runner', 'fairli']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--xYONpByes4",
        "outputId": "1ce0e52b-ec37-4dc4-d26e-2068d47cb22c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "5. Contoh Stemming (English): ['run', 'run', 'runner', 'fairli']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Lemmatization (Lebih Akurat) ---\n",
        "# Untuk Lemmatization, kita perlu tag Part-of-Speech (POS Tagging)\n",
        "# untuk hasil yang lebih baik. Namun, untuk demo dasar, kita bisa abaikan dulu.\n",
        "# NLTK WordNetLemmatizer cocok untuk bahasa Inggris.\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# Untuk bahasa Indonesia, lemmatization lebih kompleks dan sering\n",
        "# membutuhkan model POS tagging spesifik bahasa Indonesia.\n",
        "# Untuk demo ini, kita akan lewati lemmatization untuk B.Indonesia\n",
        "# dan tunjukkan contoh Inggris untuk konsepnya.\n",
        "example_words_en_lem = [\"running\", \"runs\", \"ran\", \"better\", \"geese\"]\n",
        "lemmatized_examples = [lemmatizer.lemmatize(w, pos='v') for w in example_words_en_lem] # pos='v' for verb\n",
        "lemmatized_examples_noun = [lemmatizer.lemmatize(w, pos='n') for w in example_words_en_lem] # pos='n' for noun\n",
        "print(f\"6. Contoh Lemmatization (English - Verbs): {lemmatized_examples}\") # output: ['run', 'run', 'run', 'better', 'goose'] (geese as noun)\n",
        "print(f\"6. Contoh Lemmatization (English - Nouns): {lemmatized_examples_noun}\") # output: ['running', 'run', 'ran', 'better', 'goose']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5E77X-OxXcC",
        "outputId": "470b150f-2fa8-45be-bd6b-e3c4112e6f31"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5. Contoh Lemmatization (English - Verbs): ['run', 'run', 'run', 'better', 'geese']\n",
            "5. Contoh Lemmatization (English - Nouns): ['running', 'run', 'ran', 'better', 'goose']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output akhir setelah pra-pemrosesan (untuk teks B.Indonesia kita)\n",
        "teks_bersih_akhir = \" \".join(tokens_tanpa_stopwords)\n",
        "print(f\"\\nFinal Teks Bersih (Bahasa Indonesia): {teks_bersih_akhir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii2wcOtMyBT5",
        "outputId": "554d8ded-5769-47f4-d4d5-98ad8e6e0cc2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Teks Bersih (Bahasa Indonesia): nlp bidang menarik transformatif suka belajar bandung\n"
          ]
        }
      ]
    }
  ]
}